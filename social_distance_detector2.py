# -*- coding: utf-8 -*-
"""social_distance_detector2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_KhCUxgN74G0Ww9Rn0Li3aGl0zcNL41x
"""

from packages import social_distancing_config config 
from packages.detection import detect_people 
from scipy.spatial import distance dist 
import numpy np 
import imutils 
import cv2 
import os 

# load the COCO class labels our YOLO model was trained on 
labelsPath = os.path.sep.join([config.MODEL_PATH, "coco.names"]) 
LABELS = open(labelsPath).read().strip().split("\n") 
# derive the paths to the YOLO weights and model configuration 
weightsPath = os.path.sep.join([config.MODEL_PATH, "yoLov3.weights"]: 
configPath = os.path.sep.join([config.MODEL_PATH, "yoLov3.cfg"]) 
# load our YOLO object detector trained on COCO dataset (80 classes) 
print("[INFO] Loading YOLO from disk...") 
net = cv2.dnn.readNetFromDarknet(configPath, weightsPath) 



# check if we are going to use GPU 
if config.USE_GPU: 
  print("[INFO] setting preferabLe backend and target to CUDA...") 
  net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA) 
  net.setPreferableTarget(cv2_dnn.DNN_TARGET_CUDA)

# determine only the *output* layer names that we need from YOLO 
ln = net.getLayerNames() 
ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()] 
# initialize the video stream and pointer to output video file 
print("[INFO] accessing video stream...") 
vs = cv2.VideoCapture(r"pedestrians.mp4"if "pedestrians.mp4"else 0) 
writer = None