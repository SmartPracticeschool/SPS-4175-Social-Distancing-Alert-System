# -*- coding: utf-8 -*-
"""obj_detect.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_KhCUxgN74G0Ww9Rn0Li3aGl0zcNL41x
"""

from .social_distancing_config import NMS_THRESH 
from .social distancing_config import MIN_CONF 
import numpy np 
import cv2 

def detect_people(frame, net, ln, personIdx=0):
   (H, W) = frame.shape[:2] 
   results = []

blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 41=6), swapRB=True, crop=False) 
net.setInput(blob) 
layerOutputs = net.forward(ln) 

boxes = [] 
centroids = [] 
confidences = [] 

for output in layerOutputs :
  for detection in output:
     scores = detection[5:] 
     classlD = np.argmax(scores) 
     confidence = scores[classID] 
     if classlD == personldx and confidence > MIN_CONF:
       box = detection[0:4] * np.array([W, H, W, H]) 
       (centerX, centerY, width, height)=box.astype("int") 
       x = int(centerX - (width / 2)) 
       y = int(centerY - (height / 2)) 
       boxes.append([x, y, int(width), int(height)]) 
       centroids.append((centerX, centerY))
       confidences.append(float(confidence)) 


idxs = cv2.dnn.NMSBoxes(boxes,confidences,MIN_CONF,NMS_THRESH)
if len(idxs) > 0:
  # loop over the indexes we are keeping 
  for i in idxs.flatten():
    # extract the bounding box coordinates 
    (x, y) = (boxes[i][0], boxes[i][1]) 
    (w, h) = (boxes[i][2], boxes[i][3]) 
    # update our results list to consist of the person 
    # prediction probability, bounding box coordinates, 
    # and the centroid 
    r = (confidences[i], (x, y, x + w, y + h), centroids[i] 
    results.append(r) 
# return the list of results return results